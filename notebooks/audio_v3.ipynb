{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/julian_castro/Documents/projects/audio_app/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "project_root = os.path.abspath('.')\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "import json\n",
    "from glob import glob\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from IPython.display import Audio as player\n",
    "from pydub import AudioSegment\n",
    "from pydub.utils import which\n",
    "from utils.audio import convert_mp3_to_wav, download_kaggle_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg path: /opt/homebrew/bin/ffmpeg\n",
      "ffprobe path: /opt/homebrew/bin/ffprobe\n",
      "Converted ./../data/ludwig-music-dataset-moods-and-subgenres/mp3/mp3/rock/0A4XR1HbX46wNB1HzpmA7m.mp3 to ./../data/wav/rock/0A4XR1HbX46wNB1HzpmA7m.wav\n"
     ]
    }
   ],
   "source": [
    "ffmpeg_path = \"/opt/homebrew/bin\"\n",
    "\n",
    "os.environ[\"PATH\"] += os.pathsep + ffmpeg_path\n",
    "\n",
    "AudioSegment.converter = which(\"ffmpeg\")\n",
    "AudioSegment.ffprobe = which(\"ffprobe\")\n",
    "\n",
    "print(\"ffmpeg path:\", AudioSegment.converter)\n",
    "print(\"ffprobe path:\", AudioSegment.ffprobe)\n",
    "\n",
    "path = \"./../data/ludwig-music-dataset-moods-and-subgenres/mp3/mp3/rock/0A4XR1HbX46wNB1HzpmA7m.mp3\"\n",
    "output_path = \"./../data/wav/rock/0A4XR1HbX46wNB1HzpmA7m.wav\"\n",
    "\n",
    "# Convert mp3 to wav\n",
    "convert_mp3_to_wav(path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting embeddings for facebook/wav2vec2-base-960h on 0A4XR1HbX46wNB1HzpmA7m (rock)\n",
      "Loaded /Users/julian_castro/Documents/projects/audio_app/notebooks/utils/../../data/ludwig-music-dataset-moods-and-subgenres/mp3/mp3/rock/0A4XR1HbX46wNB1HzpmA7m.mp3 with shape (479818,)\n",
      "Extracting embeddings from /Users/julian_castro/Documents/projects/audio_app/notebooks/utils/../../data/ludwig-music-dataset-moods-and-subgenres/mp3/mp3/rock/0A4XR1HbX46wNB1HzpmA7m.mp3...\n",
      "With device: mps\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of Wav2Vec2Model were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['masked_spec_embed']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded /Users/julian_castro/Documents/projects/audio_app/notebooks/utils/../../data/ludwig-music-dataset-moods-and-subgenres/mp3/mp3/rock/0A4XR1HbX46wNB1HzpmA7m.mp3 with shape (479818,)\n",
      "Audio tensor shape: (479818,)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>audio</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>metadata</th>\n",
       "      <th>identifier</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[-1.3371775e-09, -2.1358315e-09, -5.8318894e-1...</td>\n",
       "      <td>[-0.004215343, 0.025813656, -0.1028079, -0.050...</td>\n",
       "      <td>{'otherSubgenres': {'L': [{'S': ' world'}, {'S...</td>\n",
       "      <td>0A4XR1HbX46wNB1HzpmA7m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               audio  \\\n",
       "0  [-1.3371775e-09, -2.1358315e-09, -5.8318894e-1...   \n",
       "\n",
       "                                          embeddings  \\\n",
       "0  [-0.004215343, 0.025813656, -0.1028079, -0.050...   \n",
       "\n",
       "                                            metadata              identifier  \n",
       "0  {'otherSubgenres': {'L': [{'S': ' world'}, {'S...  0A4XR1HbX46wNB1HzpmA7m  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from utils.audio import get_audio_data\n",
    "import pandas as pd\n",
    "\n",
    "models = [\"facebook/wav2vec2-base-960h\"]\n",
    "tracks = [\n",
    "    {\"id\": \"0A4XR1HbX46wNB1HzpmA7m\", \"genre\": \"rock\"}\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    data = []\n",
    "    for track in tracks:\n",
    "        print(f\"Extracting embeddings for {model} on {track['id']} ({track['genre']})\")\n",
    "        track_data = get_audio_data(track[\"id\"], track[\"genre\"], model)\n",
    "        # add track data to dataframe\n",
    "        data.append(track_data)\n",
    "\n",
    "    display(pd.DataFrame(data))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoProcessor, ASTModel\n",
    "\n",
    "processor = AutoProcessor.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "model = ASTModel.from_pretrained(\"MIT/ast-finetuned-audioset-10-10-0.4593\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
